{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Wav2Vec2 model for speech recognition with Hugging Face and SageMaker\n",
    "\n",
    "## Background\n",
    "\n",
    "Wav2Vec2 is a transformer-based architecture for ASR tasks and was released in September 2020. We show its simplified architecture diagram below. For more details, see the [original paper](https://arxiv.org/abs/2006.11477). The model is composed of a multi-layer convolutional network (CNN) as feature extractor, which takes input audio signal and outputs audio representations, also considered as features. They are fed into a transformer network to generate contextualized representations. This part of training can be self-supervised, it means that the transformer can be trained with a mass of unlabeled speech and learn from them. Then the model is fine-tuned on labeled data with Connectionist Temporal Classification (CTC) algorithm for specific ASR tasks. The base model we use in this post is [Wav2Vec2-Base-960h](https://huggingface.co/facebook/wav2vec2-base-960h), it is fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. \n",
    "<img src=\"images/wav2vec2.png\">\n",
    "\n",
    "Connectionist Temporal Classification (CTC) is character-based algorithm. During the training, it’s able to demarcate each character of the transcription in the speech automatically, so the timeframe alignment is not required between audio signal and transcription. For example, one audio clip says “Hello World”, we don’t need to know in which second word “hello” is located. It saves a lot of labeling effort for ASR use cases. If you are interested in how the algorithm works underneath, see [this article](https://distill.pub/2017/ctc/) for more information.  \n",
    "\n",
    "\n",
    "## Notebook Overview \n",
    "\n",
    "In this notebook, we use [SUPERB \n",
    "(Speech processing Universal PERformance Benchmark) dataset](https://huggingface.co/datasets/superb) that available from Hugging Face Datasets library, and fine-tune the Wav2Vec2 model and deploy it as SageMaker endpoint for real-time inference for an ASR task. \n",
    "<img src=\"images/solution_overview.png\">\n",
    "\n",
    "First of all, we show how to load and preprocess the SUPERB dataset in SageMaker environment in order to obtain tokenizer and feature extractor, which are required for fine-tuning the Wav2Vec2 model. Then we use SageMaker Script Mode for training and inference steps, that allows you to define and use custom training and inference scripts and SageMaker provides supported Hugging Face framework Docker containers. For more information about training and serving Hugging Face models on SageMaker, see Use [Hugging Face with Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/hugging-face.html). This functionality is available through the development of Hugging Face [AWS Deep Learning Container (DLC)](https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/what-is-dlc.html). \n",
    "\n",
    "This notebook is tested in both SageMaker Studio and SageMaker Notebook environments. Below shows detailed setup.   \n",
    "- SageMaker Studio: **ml.m5.xlarge** instance with **Data Science** kernel.\n",
    "- SageMaker Notebook: **ml.m5.xlarge** instance with **conda_python3** kernel. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up \n",
    "First, install the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.7/site-packages (2.120.0)\n",
      "Collecting sagemaker\n",
      "  Using cached sagemaker-2.127.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (3.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (20.1)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.3.5)\n",
      "Collecting boto3<2.0,>=1.26.28\n",
      "  Using cached boto3-1.26.45-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.21.6)\n",
      "Requirement already satisfied: attrs<23,>=20.3.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (22.1.0)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.2.0)\n",
      "Collecting importlib-metadata<5.0,>=1.4.0\n",
      "  Using cached importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.0.1)\n",
      "Collecting botocore<1.30.0,>=1.29.45\n",
      "  Using cached botocore-1.29.45-py3-none-any.whl (10.3 MB)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (4.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker) (1.14.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from schema->sagemaker) (0.6.0.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.45->boto3<2.0,>=1.26.28->sagemaker) (1.26.13)\n",
      "Installing collected packages: importlib-metadata, botocore, boto3, sagemaker\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 5.1.0\n",
      "    Uninstalling importlib-metadata-5.1.0:\n",
      "      Successfully uninstalled importlib-metadata-5.1.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.24\n",
      "    Uninstalling botocore-1.29.24:\n",
      "      Successfully uninstalled botocore-1.29.24\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.26.24\n",
      "    Uninstalling boto3-1.26.24:\n",
      "      Successfully uninstalled boto3-1.26.24\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.120.0\n",
      "    Uninstalling sagemaker-2.120.0:\n",
      "      Successfully uninstalled sagemaker-2.120.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "docker-compose 1.29.2 requires PyYAML<6,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "awscli 1.27.24 requires botocore==1.29.24, but you have botocore 1.29.45 which is incompatible.\n",
      "awscli 1.27.24 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "awscli 1.27.24 requires rsa<4.8,>=3.1.2, but you have rsa 4.9 which is incompatible.\n",
      "aiobotocore 2.4.1 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.29.45 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.26.45 botocore-1.29.45 importlib-metadata-4.13.0 sagemaker-2.127.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting transformers>=4.4.2\n",
      "  Using cached transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.4.2) (20.1)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Using cached huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.4.2) (2022.10.31)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers>=4.4.2) (4.13.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=4.4.2) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.4.2) (1.21.6)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.4.2) (4.42.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers>=4.4.2) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.4.2) (6.0)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-22.0-py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers>=4.4.2) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers>=4.4.2) (3.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.4.2) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.4.2) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.4.2) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.4.2) (2022.9.24)\n",
      "Installing collected packages: tokenizers, packaging, huggingface-hub, transformers\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.1\n",
      "    Uninstalling packaging-20.1:\n",
      "      Successfully uninstalled packaging-20.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "docker-compose 1.29.2 requires PyYAML<6,>=3.10, but you have pyyaml 6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.11.1 packaging-22.0 tokenizers-0.13.2 transformers-4.25.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: s3fs in /opt/conda/lib/python3.7/site-packages (0.4.2)\n",
      "Collecting s3fs\n",
      "  Using cached s3fs-2022.11.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: fsspec==2022.11.0 in /opt/conda/lib/python3.7/site-packages (from s3fs) (2022.11.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.7/site-packages (from s3fs) (3.8.3)\n",
      "Requirement already satisfied: aiobotocore~=2.4.0 in /opt/conda/lib/python3.7/site-packages (from s3fs) (2.4.1)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in /opt/conda/lib/python3.7/site-packages (from aiobotocore~=2.4.0->s3fs) (0.11.0)\n",
      "Collecting botocore<1.27.60,>=1.27.59\n",
      "  Using cached botocore-1.27.59-py3-none-any.whl (9.1 MB)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /opt/conda/lib/python3.7/site-packages (from aiobotocore~=2.4.0->s3fs) (1.11.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (6.0.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (4.0.2)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (0.13.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (4.4.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.0->s3fs) (1.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.0->s3fs) (1.26.13)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.0->s3fs) (2.8.2)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.8)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.0->s3fs) (1.14.0)\n",
      "Installing collected packages: botocore, s3fs\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.45\n",
      "    Uninstalling botocore-1.29.45:\n",
      "      Successfully uninstalled botocore-1.29.45\n",
      "  Attempting uninstall: s3fs\n",
      "    Found existing installation: s3fs 0.4.2\n",
      "    Uninstalling s3fs-0.4.2:\n",
      "      Successfully uninstalled s3fs-0.4.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "boto3 1.26.45 requires botocore<1.30.0,>=1.29.45, but you have botocore 1.27.59 which is incompatible.\n",
      "awscli 1.27.24 requires botocore==1.29.24, but you have botocore 1.27.59 which is incompatible.\n",
      "awscli 1.27.24 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "awscli 1.27.24 requires rsa<4.8,>=3.1.2, but you have rsa 4.9 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed botocore-1.27.59 s3fs-2022.11.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting datasets\n",
      "  Using cached datasets-2.8.0-py3-none-any.whl (452 kB)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.11.0)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.11.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.13.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.28.1)\n",
      "Collecting tqdm>=4.62.1\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: dill<0.3.7 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.4.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.14.0)\n",
      "Installing collected packages: xxhash, tqdm, responses, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.42.1\n",
      "    Uninstalling tqdm-4.42.1:\n",
      "      Successfully uninstalled tqdm-4.42.1\n",
      "Successfully installed datasets-2.8.0 responses-0.18.0 tqdm-4.64.1 xxhash-3.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torch\n",
      "  Using cached torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.4.0)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.34.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (59.3.0)\n",
      "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
      "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torchaudio\n",
      "  Using cached torchaudio-0.13.1-cp37-cp37m-manylinux1_x86_64.whl (4.2 MB)\n",
      "Requirement already satisfied: torch==1.13.1 in /opt/conda/lib/python3.7/site-packages (from torchaudio) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.7/site-packages (from torch==1.13.1->torchaudio) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch==1.13.1->torchaudio) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.13.1->torchaudio) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.7/site-packages (from torch==1.13.1->torchaudio) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch==1.13.1->torchaudio) (11.7.99)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchaudio) (0.34.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchaudio) (59.3.0)\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-0.13.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.25.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tensorboard\n",
      "  Using cached tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.51.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (59.3.0)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.34.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.15.0-py2.py3-none-any.whl (177 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.21.6)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Requirement already satisfied: protobuf<4,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (3.20.3)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (2.28.1)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.14.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard) (4.13.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, werkzeug, tensorboard-data-server, pyasn1-modules, oauthlib, grpcio, cachetools, absl-py, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 1.0.0\n",
      "    Uninstalling Werkzeug-1.0.0:\n",
      "      Successfully uninstalled Werkzeug-1.0.0\n",
      "Successfully installed absl-py-1.3.0 cachetools-5.2.0 google-auth-2.15.0 google-auth-oauthlib-0.4.6 grpcio-1.51.1 markdown-3.4.1 oauthlib-3.2.2 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting wandb\n",
      "  Using cached wandb-0.13.7-py2.py3-none-any.whl (1.9 MB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.6.7)\n",
      "Collecting promise<3,>=2.0\n",
      "  Using cached promise-2.3-py3-none-any.whl\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.28.1)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Collecting setproctitle\n",
      "  Using cached setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from wandb) (59.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.20.3)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Using cached GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Using cached sentry_sdk-1.12.1-py2.py3-none-any.whl (174 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (7.0)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Using cached shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from docker-pycreds>=0.4.0->wandb) (1.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.4.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, shortuuid, setproctitle, sentry-sdk, promise, docker-pycreds, gitdb, GitPython, wandb\n",
      "Successfully installed GitPython-3.1.30 docker-pycreds-0.4.0 gitdb-4.0.10 promise-2.3 sentry-sdk-1.12.1 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 wandb-0.13.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting SoundFile\n",
      "  Using cached soundfile-0.11.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.7/site-packages (from SoundFile) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0->SoundFile) (2.19)\n",
      "Installing collected packages: SoundFile\n",
      "Successfully installed SoundFile-0.11.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 22.11.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - librosa\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    appdirs-1.4.4              |     pyh9f0ad1d_0          13 KB  conda-forge\n",
      "    audioread-3.0.0            |   py37h89c1867_0          34 KB  conda-forge\n",
      "    ca-certificates-2022.12.7  |       ha878542_0         143 KB  conda-forge\n",
      "    certifi-2022.12.7          |     pyhd8ed1ab_0         147 KB  conda-forge\n",
      "    ffmpeg-4.2                 |       h167e202_0        80.2 MB  conda-forge\n",
      "    gettext-0.19.8.1           |       h5e8e0c9_1         3.5 MB  conda-forge\n",
      "    gnutls-3.6.13              |       h85f3911_1         2.0 MB  conda-forge\n",
      "    lame-3.100                 |    h14c3975_1001         498 KB  conda-forge\n",
      "    libflac-1.3.3              |       he1b5a44_0         517 KB  conda-forge\n",
      "    libiconv-1.16              |       h516909a_0         1.4 MB  conda-forge\n",
      "    libogg-1.3.2               |    h516909a_1002         206 KB  conda-forge\n",
      "    librosa-0.8.1              |     pyhd8ed1ab_0         147 KB  conda-forge\n",
      "    libsndfile-1.0.29          |       he1b5a44_0         534 KB  conda-forge\n",
      "    libvorbis-1.3.7            |       he1b5a44_0         287 KB  conda-forge\n",
      "    nettle-3.6                 |       he412f7d_0         6.5 MB  conda-forge\n",
      "    openh264-1.8.0             |    hdbcaa40_1000         1.4 MB  conda-forge\n",
      "    pooch-1.6.0                |     pyhd8ed1ab_0          44 KB  conda-forge\n",
      "    pysoundfile-0.11.0         |     pyhd8ed1ab_0          25 KB  conda-forge\n",
      "    resampy-0.2.2              |             py_0         332 KB  conda-forge\n",
      "    x264-1!152.20180806        |       h14c3975_0         1.4 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        99.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  appdirs            conda-forge/noarch::appdirs-1.4.4-pyh9f0ad1d_0 None\n",
      "  audioread          conda-forge/linux-64::audioread-3.0.0-py37h89c1867_0 None\n",
      "  ffmpeg             conda-forge/linux-64::ffmpeg-4.2-h167e202_0 None\n",
      "  gettext            conda-forge/linux-64::gettext-0.19.8.1-h5e8e0c9_1 None\n",
      "  gnutls             conda-forge/linux-64::gnutls-3.6.13-h85f3911_1 None\n",
      "  lame               conda-forge/linux-64::lame-3.100-h14c3975_1001 None\n",
      "  libflac            conda-forge/linux-64::libflac-1.3.3-he1b5a44_0 None\n",
      "  libiconv           conda-forge/linux-64::libiconv-1.16-h516909a_0 None\n",
      "  libogg             conda-forge/linux-64::libogg-1.3.2-h516909a_1002 None\n",
      "  librosa            conda-forge/noarch::librosa-0.8.1-pyhd8ed1ab_0 None\n",
      "  libsndfile         conda-forge/linux-64::libsndfile-1.0.29-he1b5a44_0 None\n",
      "  libvorbis          conda-forge/linux-64::libvorbis-1.3.7-he1b5a44_0 None\n",
      "  nettle             conda-forge/linux-64::nettle-3.6-he412f7d_0 None\n",
      "  openh264           conda-forge/linux-64::openh264-1.8.0-hdbcaa40_1000 None\n",
      "  pooch              conda-forge/noarch::pooch-1.6.0-pyhd8ed1ab_0 None\n",
      "  pysoundfile        conda-forge/noarch::pysoundfile-0.11.0-pyhd8ed1ab_0 None\n",
      "  resampy            conda-forge/noarch::resampy-0.2.2-py_0 None\n",
      "  x264               conda-forge/linux-64::x264-1!152.20180806-h14c3975_0 None\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2022.9.24-ha878542_0 --> 2022.12.7-ha878542_0 None\n",
      "  certifi                            2022.9.24-pyhd8ed1ab_0 --> 2022.12.7-pyhd8ed1ab_0 None\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "nettle-3.6           | 6.5 MB    | ##################################### | 100% \n",
      "gettext-0.19.8.1     | 3.5 MB    | ##################################### | 100% \n",
      "libvorbis-1.3.7      | 287 KB    | ##################################### | 100% \n",
      "certifi-2022.12.7    | 147 KB    | ##################################### | 100% \n",
      "libiconv-1.16        | 1.4 MB    | ##################################### | 100% \n",
      "libflac-1.3.3        | 517 KB    | ##################################### | 100% \n",
      "x264-1!152.20180806  | 1.4 MB    | ##################################### | 100% \n",
      "lame-3.100           | 498 KB    | ##################################### | 100% \n",
      "audioread-3.0.0      | 34 KB     | ##################################### | 100% \n",
      "resampy-0.2.2        | 332 KB    | ##################################### | 100% \n",
      "openh264-1.8.0       | 1.4 MB    | ##################################### | 100% \n",
      "librosa-0.8.1        | 147 KB    | ##################################### | 100% \n",
      "pooch-1.6.0          | 44 KB     | ##################################### | 100% \n",
      "libogg-1.3.2         | 206 KB    | ##################################### | 100% \n",
      "gnutls-3.6.13        | 2.0 MB    | ##################################### | 100% \n",
      "ffmpeg-4.2           | 80.2 MB   | ##################################### | 100% \n",
      "ca-certificates-2022 | 143 KB    | ##################################### | 100% \n",
      "libsndfile-1.0.29    | 534 KB    | ##################################### | 100% \n",
      "pysoundfile-0.11.0   | 25 KB     | ##################################### | 100% \n",
      "appdirs-1.4.4        | 13 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Retrieving notices: ...working... done\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker --upgrade\n",
    "!pip install boto3 --upgrade\n",
    "!pip install \"transformers>=4.4.2\" \n",
    "!pip install s3fs --upgrade\n",
    "!pip install datasets --upgrade \n",
    "#!pip install \"librosa==0.9.1librosa\"\n",
    "!pip install torch # framework is required for transformer \n",
    "!pip install torchaudio\n",
    "!pip install transformers\n",
    "!pip install accelerate>=0.5.0\n",
    "!pip install tensorboard\n",
    "!pip install wandb\n",
    "!pip install SoundFile\n",
    "\n",
    "!conda install -y -c conda-forge librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**soundfile** library will be used to read raw audio files and convert them into arrays. Before installing **soundfile** python library, package **libsndfile** needs to be installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 22.11.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Retrieving notices: ...working... done\n",
      "Requirement already satisfied: soundfile in /opt/conda/lib/python3.7/site-packages (0.11.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.7/site-packages (from soundfile) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0->soundfile) (2.19)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge libsndfile -y\n",
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (1.26.45)\n",
      "Collecting botocore<1.30.0,>=1.29.45\n",
      "  Using cached botocore-1.29.45-py3-none-any.whl (10.3 MB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3) (0.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.45->boto3) (1.26.13)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.45->boto3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.45->boto3) (1.14.0)\n",
      "Installing collected packages: botocore\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.27.59\n",
      "    Uninstalling botocore-1.27.59:\n",
      "      Successfully uninstalled botocore-1.27.59\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.24 requires botocore==1.29.24, but you have botocore 1.29.45 which is incompatible.\n",
      "awscli 1.27.24 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "awscli 1.27.24 requires rsa<4.8,>=3.1.2, but you have rsa 4.9 which is incompatible.\n",
      "aiobotocore 2.4.1 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.29.45 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed botocore-1.29.45\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install boto3 --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Following let's import common python libraries. Create a S3 bucket in AWS console for this project, and replace **[BUCKET_NAME]** with your bucket. \n",
    "Get the execution role which allows training and servering jobs to access your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::121713061542:role/service-role/AmazonSageMaker-ExecutionRole-20220927T193257\n",
      "sagemaker bucket: pretrain-wav2vec2-on-swahili\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import numpy as np\n",
    "import random\n",
    "import soundfile \n",
    "import sagemaker\n",
    "import sagemaker.huggingface\n",
    "\n",
    "BUCKET=\"pretrain-wav2vec2-on-swahili\" # please use your bucket name\n",
    "PREFIX = \"900h-radio-2022-dataset\"\n",
    "ROLE = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=BUCKET)\n",
    "\n",
    "print(f\"sagemaker role arn: {ROLE}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log in to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd7a79549654747a8e2e46bf139c25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: mutisya. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.sagemaker_auth(path=\"./sagemaker/pretrain_wav2vec/pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "We are using SUPERB dataset for this notebook, which can be loaded from Hugging Face [dataset library](https://huggingface.co/datasets/superb) directly using `load_dataset` function. SUPERB is a leaderboard to benchmark the performance of a shared model across a wide range of speech processing tasks with minimal architecture changes and labeled data. It also includes speaker_id and chapter_id etc., these columns are removed from the dataset, and we only keep audio files and transcriptions to fine-tune the Wav2Vec2 model for an audio recognition task, which transcribes speech to text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "HF_API_TOKEN=HfFolder.get_token()\n",
    "HF_MODEL_ID=\"mutisya/wav2vec2-pretrain-swahili-radio2022-sage-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the HuggingFace model (Wav2Vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training script\n",
    "\n",
    "Here we are using SageMaker HuggingFace DLC (Deep Learning Container) script mode to construct the training and inference job, which allows you to write custom trianing and serving code and using HuggingFace framework containers that maintained and supported by AWS. \n",
    "\n",
    "When we create a training job using the script mode, the `entry_point` script, hyperparameters, its dependencies (inside requirements.txt) and input data (train and test datasets) will be copied into the container. Then it invokes the `entry_point` training script, where the train and test datasets will be loaded, training steps will be executed and model artifacts will be saved in `/opt/ml/model` in the container. After training, artifacts in this directory are uploaded to S3 for later model hosting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Estimator and start a training job\n",
    "\n",
    "Worth to highlight that, when you create a Hugging Face Estimator, you can configure hyperparameters and provide a custom parameter into the training script, such as `vocab_url` in this example. Also you can specify the metrics in the Estimator, and parse the logs of metrics and send them to CloudWatch to monitor and track the training performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job name:  huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "#create an unique id to tag training job, model name and endpoint name. \n",
    "id = int(time.time())\n",
    "\n",
    "TRAINING_JOB_NAME = f\"huggingface-wav2vec2-pretrain-swahili-radio2022-{id}\"\n",
    "print('Training job name: ', TRAINING_JOB_NAME)\n",
    "\n",
    "vocab_url = f\"s3://{BUCKET}/{PREFIX}/vocab.json\"\n",
    "# 'dataset_names':\"mutisya/swahili_radio_yt_2022_v0.1_sage_pt0 mutisya/swahili_radio_yt_2022_v0.1_sage_pt1 mutisya/swahili_radio_yt_2022_v0.1_sage_pt2 mutisya/swahili_radio_yt_2022_v0.1_sage_pt3 mutisya/swahili_radio_yt_2022_v0.1_sage_pt4 mutisya/swahili_radio_yt_2022_v0.1_sage_pt5 mutisya/swahili_radio_yt_2022_v0.1_sage_pt6 mutisya/swahili_radio_yt_2022_v0.1_sage_pt7 mutisya/swahili_radio_yt_2022_v0.1_sage_pt8 mutisya/swahili_radio_yt_2022_v0.1_sage_pt9\",\n",
    "hyperparameters = {\n",
    "    'dataset_s3_path': 's3://dataset-staging-2022/swahili_radio_yt_2022_v0.2/',\n",
    "    'dataset_split_names': \"train\", \n",
    "    'dataset_config_names': \"train\", \n",
    "    'dataset_use_auth_token' : \"True\",\n",
    "    'model_name_or_path': \"patrickvonplaten/wav2vec2-base-v2\",\n",
    "    'output_dir': \"./wav2vec2-pretrain-swahili-radio2022-1\",\n",
    "    'max_train_steps': \"20000\",\n",
    "    'num_warmup_steps': \"32000\",\n",
    "    'saving_steps': \"10000\",\n",
    "    'gradient_accumulation_steps': \"4\",\n",
    "    'learning_rate': \"0.002\",\n",
    "    'weight_decay' : \"0.01\",\n",
    "    'max_duration_in_seconds': \"30.5\",\n",
    "    'min_duration_in_seconds' : \"2.0\",\n",
    "    'logging_steps': \"1\",\n",
    "    'per_device_train_batch_size' : \"4\",\n",
    "    'per_device_eval_batch_size': \"4\",\n",
    "    'adam_beta1': \"0.9\",\n",
    "    'adam_beta2' : \"0.98\",\n",
    "    'adam_epsilon' : \"1e-06\",\n",
    "    'push_to_hub': \"True\",\n",
    "    'gradient_checkpointing': \"True\",\n",
    "    'hub_token': HF_API_TOKEN,\n",
    "    'hub_model_id': HF_MODEL_ID,\n",
    "  }\n",
    "\n",
    "# define metrics definitions\n",
    "metric_definitions=[\n",
    "        {'Name': 'val_loss', 'Regex': \"'val_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'val_contrastive_loss', 'Regex': \"'val_contrastive_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'val_diversity_loss', 'Regex': \"'val_diversity_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'val_num_losses', 'Regex': \"'val_num_losses': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'loss', 'Regex': \"'loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'contrast_loss', 'Regex': \"'contrast_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'div_loss', 'Regex': \"'div_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': '%_mask_idx', 'Regex': \"'%_mask_idx': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'ppl', 'Regex': \"'ppl': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'lr', 'Regex': \"'lr': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'temp', 'Regex': \"'temp': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'grad_norm', 'Regex': \"'grad_norm': ([0-9]+(.|e\\-)[0-9]+),?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job name:  huggingface-wav2vec2-pretrain-swahili-radio2022-1673193982\n"
     ]
    }
   ],
   "source": [
    "#create an unique id to tag training job, model name and endpoint name. \n",
    "id = int(time.time())\n",
    "\n",
    "TRAINING_JOB_NAME = f\"huggingface-wav2vec2-pretrain-swahili-radio2022-{id}\"\n",
    "print('Training job name: ', TRAINING_JOB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the [HuggingFace estimator class](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html) to train our model. When creating the estimator, the following parameters need to specify. \n",
    "\n",
    "* **entry_point**: the name of the training script. It loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model. \n",
    "* **source_dir**: the location of the training scripts. \n",
    "* **transformers_version**: the Hugging Face transformers library version we want to use.\n",
    "* **pytorch_version**: the pytorch version that compatible with transformers library. \n",
    "\n",
    "**Instance Selection**: For this use case and dataset, we use one ml.p3.2xlarge instance and the training job is able to finish within two hours. You can select a more powerful instance to reduce the training time, however it will generate more cost.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-08 22:05:23 Starting - Starting the training job...\n",
      "2023-01-08 22:05:50 Starting - Preparing the instances for training......\n",
      "2023-01-08 22:06:41 Downloading - Downloading input data.........................................................................................................................................................................................................................................................\n",
      "2023-01-08 22:48:39 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-01-08 22:48:40,624 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-01-08 22:48:40,644 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-01-08 22:48:40,645 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-01-08 22:48:40,821 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.18.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.5 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.10.2+cu113)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchaudio in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (0.10.2+cu113)\u001b[0m\n",
      "\u001b[34mCollecting accelerate>=0.5.0\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.15.0-py3-none-any.whl (191 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 191.5/191.5 kB 8.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: librosa in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (0.9.2)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard\u001b[0m\n",
      "\u001b[34mDownloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 83.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (4.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface_hub>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (0.10.0)\u001b[0m\n",
      "\u001b[34mCollecting setuptools==59.5.0\u001b[0m\n",
      "\u001b[34mDownloading setuptools-59.5.0-py3-none-any.whl (952 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 952.4/952.4 kB 105.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting wandb\u001b[0m\n",
      "\u001b[34mDownloading wandb-0.13.7-py2.py3-none-any.whl (1.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 122.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: soundfile in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (0.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3fs in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (0.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (1.24.82)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.12.0->-r requirements.txt (line 1)) (1.22.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets>=1.12.0->-r requirements.txt (line 1)) (3.8.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.12.0->-r requirements.txt (line 1)) (0.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.12.0->-r requirements.txt (line 1)) (2022.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets>=1.12.0->-r requirements.txt (line 1)) (21.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets>=1.12.0->-r requirements.txt (line 1)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.12.0->-r requirements.txt (line 1)) (9.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets>=1.12.0->-r requirements.txt (line 1)) (1.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets>=1.12.0->-r requirements.txt (line 1)) (0.70.13)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.12.0->-r requirements.txt (line 1)) (2.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.12.0->-r requirements.txt (line 1)) (4.64.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill in /opt/conda/lib/python3.8/site-packages (from datasets>=1.12.0->-r requirements.txt (line 1)) (0.3.5.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.5->-r requirements.txt (line 2)) (4.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from accelerate>=0.5.0->-r requirements.txt (line 4)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from accelerate>=0.5.0->-r requirements.txt (line 4)) (5.9.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.8/site-packages (from librosa->-r requirements.txt (line 5)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from librosa->-r requirements.txt (line 5)) (0.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numba>=0.45.1 in /opt/conda/lib/python3.8/site-packages (from librosa->-r requirements.txt (line 5)) (0.53.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.8/site-packages (from librosa->-r requirements.txt (line 5)) (1.9.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator>=4.0.10 in /opt/conda/lib/python3.8/site-packages (from librosa->-r requirements.txt (line 5)) (5.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from librosa->-r requirements.txt (line 5)) (1.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.8/site-packages (from librosa->-r requirements.txt (line 5)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.8/site-packages (from librosa->-r requirements.txt (line 5)) (1.6.0)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34mDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 119.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34mDownloading grpcio-1.51.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 56.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<4,>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorboard->-r requirements.txt (line 6)) (3.19.5)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34mDownloading google_auth-2.15.0-py2.py3-none-any.whl (177 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 177.0/177.0 kB 43.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard->-r requirements.txt (line 6)) (0.37.1)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34mDownloading absl_py-1.3.0-py3-none-any.whl (124 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.6/124.6 kB 38.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34mDownloading Markdown-3.4.1-py3-none-any.whl (93 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.3/93.3 kB 31.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard->-r requirements.txt (line 6)) (2.2.2)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 89.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 7)) (2022.9.13)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 7)) (3.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 7)) (0.0.53)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 7)) (0.13.0)\u001b[0m\n",
      "\u001b[34mCollecting docker-pycreds>=0.4.0\u001b[0m\n",
      "\u001b[34mDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting promise<3,>=2.0\u001b[0m\n",
      "\u001b[34mDownloading promise-2.3.tar.gz (19 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting pathtools\u001b[0m\n",
      "\u001b[34mDownloading pathtools-0.1.2.tar.gz (11 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting sentry-sdk>=1.0.0\u001b[0m\n",
      "\u001b[34mDownloading sentry_sdk-1.12.1-py2.py3-none-any.whl (174 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 174.3/174.3 kB 47.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting setproctitle\u001b[0m\n",
      "\u001b[34mDownloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\u001b[0m\n",
      "\u001b[34mCollecting GitPython>=1.0.0\u001b[0m\n",
      "\u001b[34mDownloading GitPython-3.1.30-py3-none-any.whl (184 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 184.0/184.0 kB 55.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting shortuuid>=0.5.0\u001b[0m\n",
      "\u001b[34mDownloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 10)) (8.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.8/site-packages (from soundfile->-r requirements.txt (line 11)) (1.15.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore>=1.12.91 in /opt/conda/lib/python3.8/site-packages (from s3fs->-r requirements.txt (line 12)) (1.27.82)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from boto3->-r requirements.txt (line 13)) (0.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3->-r requirements.txt (line 13)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.8/site-packages (from botocore>=1.12.91->s3fs->-r requirements.txt (line 12)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore>=1.12.91->s3fs->-r requirements.txt (line 12)) (1.26.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 11)) (2.21)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 10)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.12.0->-r requirements.txt (line 1)) (6.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.12.0->-r requirements.txt (line 1)) (21.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.12.0->-r requirements.txt (line 1)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.12.0->-r requirements.txt (line 1)) (2.0.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.12.0->-r requirements.txt (line 1)) (1.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.12.0->-r requirements.txt (line 1)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.12.0->-r requirements.txt (line 1)) (4.0.2)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.10-py3-none-any.whl (62 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 21.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.2.1-py3-none-any.whl (9.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34mDownloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 45.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34mDownloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 6)) (4.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/lib/python3.8/site-packages (from numba>=0.45.1->librosa->-r requirements.txt (line 5)) (0.36.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets>=1.12.0->-r requirements.txt (line 1)) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa->-r requirements.txt (line 5)) (1.4.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.12.0->-r requirements.txt (line 1)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.12.0->-r requirements.txt (line 1)) (2022.9.24)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.19.1->librosa->-r requirements.txt (line 5)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 6)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=1.12.0->-r requirements.txt (line 1)) (2022.2.1)\u001b[0m\n",
      "\u001b[34mCollecting smmap<6,>=3.0.1\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 6)) (3.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34mDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 35.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: promise, pathtools\u001b[0m\n",
      "\u001b[34mBuilding wheel for promise (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for promise (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for promise: filename=promise-2.3-py3-none-any.whl size=21486 sha256=53dcf3644f49e80057b144ef3ef31e36ea65a9d78e3b656a721c52919e9e8f86\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\u001b[0m\n",
      "\u001b[34mBuilding wheel for pathtools (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for pathtools (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8792 sha256=d39d79c087066ea99e3bba054f3700ee4b725176cabe2c864c77b2cf714a090d\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\u001b[0m\n",
      "\u001b[34mSuccessfully built promise pathtools\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tensorboard-plugin-wit, pathtools, tensorboard-data-server, smmap, shortuuid, setuptools, setproctitle, sentry-sdk, pyasn1-modules, promise, oauthlib, grpcio, docker-pycreds, cachetools, absl-py, requests-oauthlib, markdown, google-auth, gitdb, accelerate, google-auth-oauthlib, GitPython, wandb, tensorboard\u001b[0m\n",
      "\u001b[34mAttempting uninstall: setuptools\u001b[0m\n",
      "\u001b[34mFound existing installation: setuptools 65.4.0\u001b[0m\n",
      "\u001b[34mUninstalling setuptools-65.4.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled setuptools-65.4.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed GitPython-3.1.30 absl-py-1.3.0 accelerate-0.15.0 cachetools-5.2.1 docker-pycreds-0.4.0 gitdb-4.0.10 google-auth-2.15.0 google-auth-oauthlib-0.4.6 grpcio-1.51.1 markdown-3.4.1 oauthlib-3.2.2 pathtools-0.1.2 promise-2.3 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 sentry-sdk-1.12.1 setproctitle-1.3.2 setuptools-59.5.0 shortuuid-1.0.11 smmap-5.0.0 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 wandb-0.13.7\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-01-08 22:48:50,774 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-01-08 22:48:50,774 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-01-08 22:48:50,837 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"adam_beta1\": \"0.9\",\n",
      "        \"adam_beta2\": \"0.98\",\n",
      "        \"adam_epsilon\": \"1e-06\",\n",
      "        \"dataset_config_names\": \"train\",\n",
      "        \"dataset_s3_path\": \"s3://dataset-staging-2022/swahili_radio_yt_2022_v0.2/\",\n",
      "        \"dataset_split_names\": \"train\",\n",
      "        \"dataset_use_auth_token\": \"True\",\n",
      "        \"gradient_accumulation_steps\": \"4\",\n",
      "        \"gradient_checkpointing\": \"True\",\n",
      "        \"hub_model_id\": \"mutisya/wav2vec2-pretrain-swahili-radio2022-sage-1\",\n",
      "        \"hub_token\": \"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\",\n",
      "        \"learning_rate\": \"0.002\",\n",
      "        \"logging_steps\": \"1\",\n",
      "        \"max_duration_in_seconds\": \"30.5\",\n",
      "        \"max_train_steps\": \"20000\",\n",
      "        \"min_duration_in_seconds\": \"2.0\",\n",
      "        \"model_name_or_path\": \"patrickvonplaten/wav2vec2-base-v2\",\n",
      "        \"num_warmup_steps\": \"32000\",\n",
      "        \"output_dir\": \"./wav2vec2-pretrain-swahili-radio2022-1\",\n",
      "        \"per_device_eval_batch_size\": \"4\",\n",
      "        \"per_device_train_batch_size\": \"4\",\n",
      "        \"push_to_hub\": \"True\",\n",
      "        \"saving_steps\": \"10000\",\n",
      "        \"weight_decay\": \"0.01\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://pretrain-wav2vec2-on-swahili/huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_wav2vec2_pretraining_no_trainer_sagemaker\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_wav2vec2_pretraining_no_trainer_sagemaker.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"adam_beta1\":\"0.9\",\"adam_beta2\":\"0.98\",\"adam_epsilon\":\"1e-06\",\"dataset_config_names\":\"train\",\"dataset_s3_path\":\"s3://dataset-staging-2022/swahili_radio_yt_2022_v0.2/\",\"dataset_split_names\":\"train\",\"dataset_use_auth_token\":\"True\",\"gradient_accumulation_steps\":\"4\",\"gradient_checkpointing\":\"True\",\"hub_model_id\":\"mutisya/wav2vec2-pretrain-swahili-radio2022-sage-1\",\"hub_token\":\"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\",\"learning_rate\":\"0.002\",\"logging_steps\":\"1\",\"max_duration_in_seconds\":\"30.5\",\"max_train_steps\":\"20000\",\"min_duration_in_seconds\":\"2.0\",\"model_name_or_path\":\"patrickvonplaten/wav2vec2-base-v2\",\"num_warmup_steps\":\"32000\",\"output_dir\":\"./wav2vec2-pretrain-swahili-radio2022-1\",\"per_device_eval_batch_size\":\"4\",\"per_device_train_batch_size\":\"4\",\"push_to_hub\":\"True\",\"saving_steps\":\"10000\",\"weight_decay\":\"0.01\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_wav2vec2_pretraining_no_trainer_sagemaker.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_wav2vec2_pretraining_no_trainer_sagemaker\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://pretrain-wav2vec2-on-swahili/huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"adam_beta1\":\"0.9\",\"adam_beta2\":\"0.98\",\"adam_epsilon\":\"1e-06\",\"dataset_config_names\":\"train\",\"dataset_s3_path\":\"s3://dataset-staging-2022/swahili_radio_yt_2022_v0.2/\",\"dataset_split_names\":\"train\",\"dataset_use_auth_token\":\"True\",\"gradient_accumulation_steps\":\"4\",\"gradient_checkpointing\":\"True\",\"hub_model_id\":\"mutisya/wav2vec2-pretrain-swahili-radio2022-sage-1\",\"hub_token\":\"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\",\"learning_rate\":\"0.002\",\"logging_steps\":\"1\",\"max_duration_in_seconds\":\"30.5\",\"max_train_steps\":\"20000\",\"min_duration_in_seconds\":\"2.0\",\"model_name_or_path\":\"patrickvonplaten/wav2vec2-base-v2\",\"num_warmup_steps\":\"32000\",\"output_dir\":\"./wav2vec2-pretrain-swahili-radio2022-1\",\"per_device_eval_batch_size\":\"4\",\"per_device_train_batch_size\":\"4\",\"push_to_hub\":\"True\",\"saving_steps\":\"10000\",\"weight_decay\":\"0.01\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://pretrain-wav2vec2-on-swahili/huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516/source/sourcedir.tar.gz\",\"module_name\":\"run_wav2vec2_pretraining_no_trainer_sagemaker\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_wav2vec2_pretraining_no_trainer_sagemaker.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--adam_beta1\",\"0.9\",\"--adam_beta2\",\"0.98\",\"--adam_epsilon\",\"1e-06\",\"--dataset_config_names\",\"train\",\"--dataset_s3_path\",\"s3://dataset-staging-2022/swahili_radio_yt_2022_v0.2/\",\"--dataset_split_names\",\"train\",\"--dataset_use_auth_token\",\"True\",\"--gradient_accumulation_steps\",\"4\",\"--gradient_checkpointing\",\"True\",\"--hub_model_id\",\"mutisya/wav2vec2-pretrain-swahili-radio2022-sage-1\",\"--hub_token\",\"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\",\"--learning_rate\",\"0.002\",\"--logging_steps\",\"1\",\"--max_duration_in_seconds\",\"30.5\",\"--max_train_steps\",\"20000\",\"--min_duration_in_seconds\",\"2.0\",\"--model_name_or_path\",\"patrickvonplaten/wav2vec2-base-v2\",\"--num_warmup_steps\",\"32000\",\"--output_dir\",\"./wav2vec2-pretrain-swahili-radio2022-1\",\"--per_device_eval_batch_size\",\"4\",\"--per_device_train_batch_size\",\"4\",\"--push_to_hub\",\"True\",\"--saving_steps\",\"10000\",\"--weight_decay\",\"0.01\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_ADAM_BETA1=0.9\u001b[0m\n",
      "\u001b[34mSM_HP_ADAM_BETA2=0.98\u001b[0m\n",
      "\u001b[34mSM_HP_ADAM_EPSILON=1e-06\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_CONFIG_NAMES=train\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_S3_PATH=s3://dataset-staging-2022/swahili_radio_yt_2022_v0.2/\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_SPLIT_NAMES=train\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_USE_AUTH_TOKEN=True\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=4\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=True\u001b[0m\n",
      "\u001b[34mSM_HP_HUB_MODEL_ID=mutisya/wav2vec2-pretrain-swahili-radio2022-sage-1\u001b[0m\n",
      "\u001b[34mSM_HP_HUB_TOKEN=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\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.002\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=1\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DURATION_IN_SECONDS=30.5\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_TRAIN_STEPS=20000\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_DURATION_IN_SECONDS=2.0\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME_OR_PATH=patrickvonplaten/wav2vec2-base-v2\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_WARMUP_STEPS=32000\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=./wav2vec2-pretrain-swahili-radio2022-1\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_EVAL_BATCH_SIZE=4\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=4\u001b[0m\n",
      "\u001b[34mSM_HP_PUSH_TO_HUB=True\u001b[0m\n",
      "\u001b[34mSM_HP_SAVING_STEPS=10000\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT_DECAY=0.01\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.22b20220929-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 run_wav2vec2_pretraining_no_trainer_sagemaker.py --adam_beta1 0.9 --adam_beta2 0.98 --adam_epsilon 1e-06 --dataset_config_names train --dataset_s3_path s3://dataset-staging-2022/swahili_radio_yt_2022_v0.2/ --dataset_split_names train --dataset_use_auth_token True --gradient_accumulation_steps 4 --gradient_checkpointing True --hub_model_id mutisya/wav2vec2-pretrain-swahili-radio2022-sage-1 --hub_token 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 --learning_rate 0.002 --logging_steps 1 --max_duration_in_seconds 30.5 --max_train_steps 20000 --min_duration_in_seconds 2.0 --model_name_or_path patrickvonplaten/wav2vec2-base-v2 --num_warmup_steps 32000 --output_dir ./wav2vec2-pretrain-swahili-radio2022-1 --per_device_eval_batch_size 4 --per_device_train_batch_size 4 --push_to_hub True --saving_steps 10000 --weight_decay 0.01\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\u001b[0m\n",
      "\u001b[34mwandb: Currently logged in as: mutisya. Use `wandb login --relogin` to force relogin\u001b[0m\n",
      "\u001b[34mwandb: - Waiting for wandb.init()...\u001b[0m\n",
      "\u001b[34mwandb: \\ Waiting for wandb.init()...\u001b[0m\n",
      "\u001b[34mwandb: Tracking run with wandb version 0.13.7\u001b[0m\n",
      "\u001b[34mwandb: Run data is saved locally in /opt/ml/code/wandb/run-20230108_224855-huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516-acmbbn-algo-1\u001b[0m\n",
      "\u001b[34mwandb: Run `wandb offline` to turn off syncing.\u001b[0m\n",
      "\u001b[34mwandb: Syncing run huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516-acmbbn-algo-1\u001b[0m\n",
      "\u001b[34mwandb: ⭐️ View project at https://wandb.ai/mutisya/wav2vec2-pretrain-swahili-radio2022-1\u001b[0m\n",
      "\u001b[34mwandb: 🚀 View run at https://wandb.ai/mutisya/wav2vec2-pretrain-swahili-radio2022-1/runs/huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516-acmbbn-algo-1\u001b[0m\n",
      "\u001b[34mCloning https://huggingface.co/mutisya/wav2vec2-pretrain-swahili-radio2022-sage-1 into local empty directory.\u001b[0m\n",
      "\u001b[34mRun install_sndfile.sh\u001b[0m\n",
      "\u001b[34mchecking whether configure should try to set CFLAGS/CXXFLAGS/CPPFLAGS/LDFLAGS... yes\u001b[0m\n",
      "\u001b[34mchecking build system type... x86_64-pc-linux-gnu\u001b[0m\n",
      "\u001b[34mchecking host system type... x86_64-pc-linux-gnu\u001b[0m\n",
      "\u001b[34mchecking for a BSD-compatible install... /usr/bin/install -c\u001b[0m\n",
      "\u001b[34mchecking whether build environment is sane... yes\u001b[0m\n",
      "\u001b[34mchecking for a thread-safe mkdir -p... /usr/bin/mkdir -p\u001b[0m\n",
      "\u001b[34mchecking for gawk... no\u001b[0m\n",
      "\u001b[34mchecking for mawk... mawk\u001b[0m\n",
      "\u001b[34mchecking whether make sets $(MAKE)... yes\u001b[0m\n",
      "\u001b[34mchecking whether make supports nested variables... yes\u001b[0m\n",
      "\u001b[34mchecking whether make supports nested variables... (cached) yes\u001b[0m\n",
      "\u001b[34mchecking for gcc... gcc\u001b[0m\n",
      "\u001b[34mchecking whether the C compiler works... yes\u001b[0m\n",
      "\u001b[34mchecking for C compiler default output file name... a.out\u001b[0m\n",
      "\u001b[34mchecking for suffix of executables... \u001b[0m\n",
      "\u001b[34mchecking whether we are cross compiling... no\u001b[0m\n",
      "\u001b[34mchecking for suffix of object files... o\u001b[0m\n",
      "\u001b[34mchecking whether we are using the GNU C compiler... yes\u001b[0m\n",
      "\u001b[34mchecking whether gcc accepts -g... yes\u001b[0m\n",
      "\u001b[34mchecking for gcc option to accept ISO C89... none needed\u001b[0m\n",
      "\u001b[34mchecking whether gcc understands -c and -o together... yes\u001b[0m\n",
      "\u001b[34mchecking whether make supports the include directive... yes (GNU style)\u001b[0m\n",
      "\u001b[34mchecking dependency style of gcc... gcc3\u001b[0m\n",
      "\u001b[34mchecking for gcc option to accept ISO C99... none needed\u001b[0m\n",
      "\u001b[34mchecking how to run the C preprocessor... gcc -E\u001b[0m\n",
      "\u001b[34mchecking for grep that handles long lines and -e... /usr/bin/grep\u001b[0m\n",
      "\u001b[34mchecking for egrep... /usr/bin/grep -E\u001b[0m\n",
      "\u001b[34mchecking for ANSI C header files... yes\u001b[0m\n",
      "\u001b[34mchecking for sys/types.h... yes\u001b[0m\n",
      "\u001b[34mchecking for sys/stat.h... yes\u001b[0m\n",
      "\u001b[34mchecking for stdlib.h... yes\u001b[0m\n",
      "\u001b[34mchecking for string.h... yes\u001b[0m\n",
      "\u001b[34mchecking for memory.h... yes\u001b[0m\n",
      "\u001b[34mchecking for strings.h... yes\u001b[0m\n",
      "\u001b[34mchecking for inttypes.h... yes\u001b[0m\n",
      "\u001b[34mchecking for stdint.h... yes\u001b[0m\n",
      "\u001b[34mchecking for unistd.h... yes\u001b[0m\n",
      "\u001b[34mchecking minix/config.h usability... no\u001b[0m\n",
      "\u001b[34mchecking minix/config.h presence... no\u001b[0m\n",
      "\u001b[34mchecking for minix/config.h... no\u001b[0m\n",
      "\u001b[34mchecking whether it is safe to define __EXTENSIONS__... yes\u001b[0m\n",
      "\u001b[34mchecking for g++... g++\u001b[0m\n",
      "\u001b[34mchecking whether we are using the GNU C++ compiler... yes\u001b[0m\n",
      "\u001b[34mchecking whether g++ accepts -g... yes\u001b[0m\n",
      "\u001b[34mchecking dependency style of g++... gcc3\u001b[0m\n",
      "\u001b[34mchecking for C compiler vendor... gnu\u001b[0m\n",
      "\u001b[34mchecking for a sed that does not truncate output... /usr/bin/sed\u001b[0m\n",
      "\u001b[34mchecking for C compiler version... 9.4.0\u001b[0m\n",
      "\u001b[34mchecking for C++ compiler vendor... gnu\u001b[0m\n",
      "\u001b[34mchecking for C++ compiler version... 9.4.0\u001b[0m\n",
      "\u001b[34mchecking for a sed that does not truncate output... (cached) /usr/bin/sed\u001b[0m\n",
      "\u001b[34mchecking for ar... ar\u001b[0m\n",
      "\u001b[34mchecking the archiver (ar) interface... ar\u001b[0m\n",
      "\u001b[34mchecking how to print strings... printf\u001b[0m\n",
      "\u001b[34mchecking for a sed that does not truncate output... (cached) /usr/bin/sed\u001b[0m\n",
      "\u001b[34mchecking for fgrep... /usr/bin/grep -F\u001b[0m\n",
      "\u001b[34mchecking for ld used by gcc... /usr/bin/ld\u001b[0m\n",
      "\u001b[34mchecking if the linker (/usr/bin/ld) is GNU ld... yes\u001b[0m\n",
      "\u001b[34mchecking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\u001b[0m\n",
      "\u001b[34mchecking the name lister (/usr/bin/nm -B) interface... BSD nm\u001b[0m\n",
      "\u001b[34mchecking whether ln -s works... yes\u001b[0m\n",
      "\u001b[34mchecking the maximum length of command line arguments... 1966080\u001b[0m\n",
      "\u001b[34mchecking how to convert x86_64-pc-linux-gnu file names to x86_64-pc-linux-gnu format... func_convert_file_noop\u001b[0m\n",
      "\u001b[34mchecking how to convert x86_64-pc-linux-gnu file names to toolchain format... func_convert_file_noop\u001b[0m\n",
      "\u001b[34mchecking for /usr/bin/ld option to reload object files... -r\u001b[0m\n",
      "\u001b[34mchecking for objdump... objdump\u001b[0m\n",
      "\u001b[34mchecking how to recognize dependent libraries... pass_all\u001b[0m\n",
      "\u001b[34mchecking for dlltool... no\u001b[0m\n",
      "\u001b[34mchecking how to associate runtime and link libraries... printf %s\\n\u001b[0m\n",
      "\u001b[34mchecking for archiver @FILE support... @\u001b[0m\n",
      "\u001b[34mchecking for strip... strip\u001b[0m\n",
      "\u001b[34mchecking for ranlib... ranlib\u001b[0m\n",
      "\u001b[34mchecking command to parse /usr/bin/nm -B output from gcc object... ok\u001b[0m\n",
      "\u001b[34mchecking for sysroot... no\u001b[0m\n",
      "\u001b[34mchecking for a working dd... /usr/bin/dd\u001b[0m\n",
      "\u001b[34mchecking how to truncate binary pipes... /usr/bin/dd bs=4096 count=1\u001b[0m\n",
      "\u001b[34mchecking for mt... no\u001b[0m\n",
      "\u001b[34mchecking if : is a manifest tool... no\u001b[0m\n",
      "\u001b[34mchecking for dlfcn.h... yes\u001b[0m\n",
      "\u001b[34mchecking for objdir... .libs\u001b[0m\n",
      "\u001b[34mchecking if gcc supports -fno-rtti -fno-exceptions... no\u001b[0m\n",
      "\u001b[34mchecking for gcc option to produce PIC... -fPIC -DPIC\u001b[0m\n",
      "\u001b[34mchecking if gcc PIC flag -fPIC -DPIC works... yes\u001b[0m\n",
      "\u001b[34mchecking if gcc static flag -static works... yes\u001b[0m\n",
      "\u001b[34mchecking if gcc supports -c -o file.o... yes\u001b[0m\n",
      "\u001b[34mchecking if gcc supports -c -o file.o... (cached) yes\u001b[0m\n",
      "\u001b[34mchecking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\u001b[0m\n",
      "\u001b[34mchecking whether -lc should be explicitly linked in... no\u001b[0m\n",
      "\u001b[34mchecking dynamic linker characteristics... GNU/Linux ld.so\u001b[0m\n",
      "\u001b[34mchecking how to hardcode library paths into programs... immediate\u001b[0m\n",
      "\u001b[34mchecking whether stripping libraries is possible... yes\u001b[0m\n",
      "\u001b[34mchecking if libtool supports shared libraries... yes\u001b[0m\n",
      "\u001b[34mchecking whether to build shared libraries... yes\u001b[0m\n",
      "\u001b[34mchecking whether to build static libraries... yes\u001b[0m\n",
      "\u001b[34mchecking how to run the C++ preprocessor... g++ -E\u001b[0m\n",
      "\u001b[34mchecking for ld used by g++... /usr/bin/ld -m elf_x86_64\u001b[0m\n",
      "\u001b[34mchecking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes\u001b[0m\n",
      "\u001b[34mchecking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\u001b[0m\n",
      "\u001b[34mchecking for g++ option to produce PIC... -fPIC -DPIC\u001b[0m\n",
      "\u001b[34mchecking if g++ PIC flag -fPIC -DPIC works... yes\u001b[0m\n",
      "\u001b[34mchecking if g++ static flag -static works... yes\u001b[0m\n",
      "\u001b[34mchecking if g++ supports -c -o file.o... yes\u001b[0m\n",
      "\u001b[34mchecking if g++ supports -c -o file.o... (cached) yes\u001b[0m\n",
      "\u001b[34mchecking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\u001b[0m\n",
      "\u001b[34mchecking dynamic linker characteristics... (cached) GNU/Linux ld.so\u001b[0m\n",
      "\u001b[34mchecking how to hardcode library paths into programs... immediate\u001b[0m\n",
      "\u001b[34mchecking for windres... no\u001b[0m\n",
      "\u001b[34mchecking whether ln -s works... yes\u001b[0m\n",
      "\u001b[34mchecking for python... /opt/conda/bin/python\u001b[0m\n",
      "\u001b[34mchecking for python version... 3.8\u001b[0m\n",
      "\u001b[34mchecking for python platform... linux\u001b[0m\n",
      "\u001b[34mchecking for python script directory... ${prefix}/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mchecking for python extension module directory... ${exec_prefix}/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mchecking for autogen... no\u001b[0m\n",
      "\u001b[34mchecking for wine... no\u001b[0m\n",
      "\u001b[34mchecking for xcode-select... no\u001b[0m\n",
      "\u001b[34mchecking for ANSI C header files... (cached) yes\u001b[0m\n",
      "\u001b[34mchecking endian.h usability... yes\u001b[0m\n",
      "\u001b[34mchecking endian.h presence... yes\u001b[0m\n",
      "\u001b[34mchecking for endian.h... yes\u001b[0m\n",
      "\u001b[34mchecking byteswap.h usability... yes\u001b[0m\n",
      "\u001b[34mchecking byteswap.h presence... yes\u001b[0m\n",
      "\u001b[34mchecking for byteswap.h... yes\u001b[0m\n",
      "\u001b[34mchecking locale.h usability... yes\u001b[0m\n",
      "\u001b[34mchecking locale.h presence... yes\u001b[0m\n",
      "\u001b[34mchecking for locale.h... yes\u001b[0m\n",
      "\u001b[34mchecking sys/time.h usability... yes\u001b[0m\n",
      "\u001b[34mchecking sys/time.h presence... yes\u001b[0m\n",
      "\u001b[34mchecking for sys/time.h... yes\u001b[0m\n",
      "\u001b[34mchecking immintrin.h usability... yes\u001b[0m\n",
      "\u001b[34mchecking immintrin.h presence... yes\u001b[0m\n",
      "\u001b[34mchecking for immintrin.h... yes\u001b[0m\n",
      "\u001b[34mchecking for sys/wait.h that is POSIX.1 compatible... yes\u001b[0m\n",
      "\u001b[34mchecking whether S_IRGRP is declared... yes\u001b[0m\n",
      "\u001b[34mchecking size of wchar_t... 4\u001b[0m\n",
      "\u001b[34mchecking size of short... 2\u001b[0m\n",
      "\u001b[34mchecking size of int... 4\u001b[0m\n",
      "\u001b[34mchecking size of long... 8\u001b[0m\n",
      "\u001b[34mchecking size of float... 4\u001b[0m\n",
      "\u001b[34mchecking size of double... 8\u001b[0m\n",
      "\u001b[34mchecking size of void*... 8\u001b[0m\n",
      "\u001b[34mchecking size of size_t... 8\u001b[0m\n",
      "\u001b[34mchecking size of int64_t... 8\u001b[0m\n",
      "\u001b[34mchecking size of long long... 8\u001b[0m\n",
      "\u001b[34mchecking size of off_t... 8\u001b[0m\n",
      "\u001b[34mchecking for ssize_t... yes\u001b[0m\n",
      "\u001b[34mchecking whether byte ordering is bigendian... no\u001b[0m\n",
      "\u001b[34mchecking for malloc... yes\u001b[0m\n",
      "\u001b[34mchecking for calloc... yes\u001b[0m\n",
      "\u001b[34mchecking for realloc... yes\u001b[0m\n",
      "\u001b[34mchecking for free... yes\u001b[0m\n",
      "\u001b[34mchecking for open... yes\u001b[0m\n",
      "\u001b[34mchecking for read... yes\u001b[0m\n",
      "\u001b[34mchecking for write... yes\u001b[0m\n",
      "\u001b[34mchecking for lseek... yes\u001b[0m\n",
      "\u001b[34mchecking for lseek64... yes\u001b[0m\n",
      "\u001b[34mchecking for fstat... yes\u001b[0m\n",
      "\u001b[34mchecking for fstat64... yes\u001b[0m\n",
      "\u001b[34mchecking for ftruncate... yes\u001b[0m\n",
      "\u001b[34mchecking for fsync... yes\u001b[0m\n",
      "\u001b[34mchecking for snprintf... yes\u001b[0m\n",
      "\u001b[34mchecking for vsnprintf... yes\u001b[0m\n",
      "\u001b[34mchecking for gmtime... yes\u001b[0m\n",
      "\u001b[34mchecking for gmtime_r... yes\u001b[0m\n",
      "\u001b[34mchecking for localtime... yes\u001b[0m\n",
      "\u001b[34mchecking for localtime_r... yes\u001b[0m\n",
      "\u001b[34mchecking for gettimeofday... yes\u001b[0m\n",
      "\u001b[34mchecking for mmap... yes\u001b[0m\n",
      "\u001b[34mchecking for getpagesize... yes\u001b[0m\n",
      "\u001b[34mchecking for setlocale... yes\u001b[0m\n",
      "\u001b[34mchecking for pipe... yes\u001b[0m\n",
      "\u001b[34mchecking for waitpid... yes\u001b[0m\n",
      "\u001b[34mchecking for library containing floor... -lm\u001b[0m\n",
      "\u001b[34mchecking for floor... yes\u001b[0m\n",
      "\u001b[34mchecking for ceil... yes\u001b[0m\n",
      "\u001b[34mchecking for fmod... yes\u001b[0m\n",
      "\u001b[34mchecking for lrint... yes\u001b[0m\n",
      "\u001b[34mchecking for lrintf... yes\u001b[0m\n",
      "\u001b[34mchecking for octave... no\u001b[0m\n",
      "\u001b[34mchecking for mkoctfile... no\u001b[0m\n",
      "\u001b[34mchecking for octave-config... no\u001b[0m\n",
      "\u001b[34mchecking for pkg-config... no\u001b[0m\n",
      "\u001b[34mchecking for sqlite3 >= 3.2 ... checking processor clipping capabilities... none\u001b[0m\n",
      "\u001b[34mchecking for ALSA... no\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -O2... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -pipe... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -O2... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -pipe... yes\u001b[0m\n",
      "\u001b[34mchecking whether the linker accepts -Wl,-O1... yes\u001b[0m\n",
      "\u001b[34mchecking whether the linker accepts -Wl,--as-needed... yes\u001b[0m\n",
      "\u001b[34mchecking whether the linker accepts -Wl,--no-undefined... yes\u001b[0m\n",
      "\u001b[34mchecking whether the linker accepts -Wl,--gc-sections... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Wall... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Wextra... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Wpointer-arith... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Wcast-align... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Wcast-qual... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Wshadow... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Wwrite-strings... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Wundef... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Wuninitialized... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Winit-self... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Wno-format-truncation... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Wvla... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Wbad-function-cast... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Wnested-externs... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Wstrict-prototypes... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Wmissing-prototypes... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Wmissing-declarations... yes\u001b[0m\n",
      "\u001b[34mchecking whether C compiler accepts -Waggregate-return... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -Wall... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -Wextra... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -Wpointer-arith... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -Wcast-align... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -Wcast-qual... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -Wshadow... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -Wwrite-strings... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -Wundef... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -Wuninitialized... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -Winit-self... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -Wno-format-truncation... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -Wctor-dtor-privacy... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -Wnon-virtual-dtor... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -Woverloaded-virtual... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -Wreorder... yes\u001b[0m\n",
      "\u001b[34mchecking whether C++ compiler accepts -Wsign-promo... yes\u001b[0m\n",
      "\u001b[34mchecking whether to add -D_FORTIFY_SOURCE=2 to CPPFLAGS... no\u001b[0m\n",
      "\u001b[34mchecking that generated files are newer than configure... done\u001b[0m\n",
      "\u001b[34mconfigure: creating ./config.status\u001b[0m\n",
      "\u001b[34mconfig.status: creating Makefile\u001b[0m\n",
      "\u001b[34mconfig.status: creating Octave/Makefile\u001b[0m\n",
      "\u001b[34mconfig.status: creating src/version-metadata.rc\u001b[0m\n",
      "\u001b[34mconfig.status: creating include/sndfile.h\u001b[0m\n",
      "\u001b[34mconfig.status: creating tests/test_wrapper.sh\u001b[0m\n",
      "\u001b[34mconfig.status: creating tests/pedantic-header-test.sh\u001b[0m\n",
      "\u001b[34mconfig.status: creating libsndfile.spec\u001b[0m\n",
      "\u001b[34mconfig.status: creating sndfile.pc\u001b[0m\n",
      "\u001b[34mconfig.status: creating Scripts/build-test-tarball.mk\u001b[0m\n",
      "\u001b[34mconfig.status: creating src/config.h\u001b[0m\n",
      "\u001b[34mconfig.status: executing depfiles commands\u001b[0m\n",
      "\u001b[34mconfig.status: executing libtool commands\n",
      "    *****************************************************************\n",
      "    ***          The pkg-config program is missing.               ***\n",
      "    *** External FLAC/Ogg/Vorbis libs cannot be found without it. ***\n",
      "    ***       http://pkg-config.freedesktop.org/wiki/             ***\n",
      "    *****************************************************************\u001b[0m\n",
      "\u001b[34m-=-=-=-=-=-=-=-=-=-= Configuration Complete =-=-=-=-=-=-=-=-=-=-=-\n",
      "  Configuration summary :\n",
      "    libsndfile version : .................. 1.0.31\n",
      "    Host CPU : ............................ x86_64\n",
      "    Host Vendor : ......................... pc\n",
      "    Host OS : ............................. linux-gnu\n",
      "    CFLAGS : ..............................  -O2 -pipe -Wall -Wextra -Wpointer-arith -Wcast-align -Wcast-qual -Wshadow -Wwrite-strings -Wundef -Wuninitialized -Winit-self -Wno-format-truncation -Wvla -Wbad-function-cast -Wnested-externs -Wstrict-prototypes -Wmissing-prototypes -Wmissing-declarations -Waggregate-return \n",
      "    CXXFLAGS : ............................  -O2 -pipe -Wall -Wextra -Wpointer-arith -Wcast-align -Wcast-qual -Wshadow -Wwrite-strings -Wundef -Wuninitialized -Winit-self -Wno-format-truncation -Wctor-dtor-privacy -Wnon-virtual-dtor -Woverloaded-virtual -Wreorder -Wsign-promo\n",
      "    CPPFLAGS : ............................ \n",
      "    LDFLAGS : .............................  -Wl,-O1 -Wl,--as-needed -Wl,--no-undefined -Wl,--gc-sections\n",
      "    Experimental code : ................... no\n",
      "    Using ALSA in example programs : ...... no (auto)\n",
      "    External FLAC/Ogg/Vorbis/Opus : ....... no\n",
      "    Building Octave interface : ........... no\n",
      "  Tools :\n",
      "    C Compiler Vendor is : ................ gnu (9.4.0)\n",
      "    CXX Compiler Vendor is : .............. gnu (9.4.0)\n",
      "    Sanitizer enabled : ................... no\n",
      "    Stack smash protection : .............. no\n",
      "  Installation directories :\n",
      "    Library directory : ................... /usr/local/lib\n",
      "    Program directory : ................... /usr/local/bin\n",
      "    Pkgconfig directory : ................. /usr/local/lib/pkgconfig\n",
      "    HTML docs directory : ................. /usr/local/share/doc/libsndfile\u001b[0m\n",
      "\u001b[34mCompiling some other packages against libsndfile may require\u001b[0m\n",
      "\u001b[34mthe addition of '/usr/local/lib/pkgconfig' to the\u001b[0m\n",
      "\u001b[34mPKG_CONFIG_PATH environment variable.\u001b[0m\n",
      "\u001b[34mmake  all-recursive\u001b[0m\n",
      "\u001b[34mmake[1]: Entering directory '/opt/ml/code/libsndfile-1.0.31'\u001b[0m\n",
      "\u001b[34mmake[2]: Entering directory '/opt/ml/code/libsndfile-1.0.31'\n",
      "  CC       programs/sndfile-info.o\n",
      "  CC       programs/common.o\n",
      "  CC       src/libsndfile_la-sndfile.lo\n",
      "  CC       src/libsndfile_la-aiff.lo\n",
      "  CC       src/libsndfile_la-au.lo\n",
      "  CC       src/libsndfile_la-avr.lo\n",
      "  CC       src/libsndfile_la-caf.lo\n",
      "  CC       src/libsndfile_la-dwd.lo\n",
      "  CC       src/libsndfile_la-flac.lo\n",
      "  CC       src/libsndfile_la-g72x.lo\n",
      "  CC       src/libsndfile_la-htk.lo\n",
      "  CC       src/libsndfile_la-ircam.lo\n",
      "  CC       src/libsndfile_la-macos.lo\n",
      "  CC       src/libsndfile_la-mat4.lo\n",
      "  CC       src/libsndfile_la-mat5.lo\n",
      "  CC       src/libsndfile_la-nist.lo\n",
      "  CC       src/libsndfile_la-paf.lo\n",
      "  CC       src/libsndfile_la-pvf.lo\n",
      "  CC       src/libsndfile_la-raw.lo\n",
      "  CC       src/libsndfile_la-rx2.lo\n",
      "  CC       src/libsndfile_la-sd2.lo\n",
      "  CC       src/libsndfile_la-sds.lo\n",
      "  CC       src/libsndfile_la-svx.lo\n",
      "  CC       src/libsndfile_la-txw.lo\n",
      "  CC       src/libsndfile_la-voc.lo\n",
      "  CC       src/libsndfile_la-wve.lo\n",
      "  CC       src/libsndfile_la-w64.lo\n",
      "  CC       src/libsndfile_la-wavlike.lo\n",
      "  CC       src/libsndfile_la-wav.lo\n",
      "  CC       src/libsndfile_la-xi.lo\n",
      "  CC       src/libsndfile_la-mpc2k.lo\n",
      "  CC       src/libsndfile_la-rf64.lo\n",
      "  CC       src/libsndfile_la-ogg_vorbis.lo\n",
      "  CC       src/libsndfile_la-ogg_speex.lo\n",
      "  CC       src/libsndfile_la-ogg_pcm.lo\n",
      "  CC       src/libsndfile_la-ogg_opus.lo\n",
      "  CC       src/libsndfile_la-ogg_vcomment.lo\n",
      "  CC       src/GSM610/add.lo\n",
      "  CC       src/GSM610/code.lo\n",
      "  CC       src/GSM610/decode.lo\n",
      "  CC       src/GSM610/gsm_create.lo\n",
      "  CC       src/GSM610/gsm_decode.lo\n",
      "  CC       src/GSM610/gsm_destroy.lo\n",
      "  CC       src/GSM610/gsm_encode.lo\n",
      "  CC       src/GSM610/gsm_option.lo\n",
      "  CC       src/GSM610/long_term.lo\n",
      "  CC       src/GSM610/lpc.lo\n",
      "  CC       src/GSM610/preprocess.lo\n",
      "  CC       src/GSM610/rpe.lo\n",
      "  CC       src/GSM610/short_term.lo\n",
      "  CC       src/GSM610/table.lo\n",
      "  CCLD     src/GSM610/libgsm.la\n",
      "  CC       src/G72x/g721.lo\n",
      "  CC       src/G72x/g723_16.lo\n",
      "  CC       src/G72x/g723_24.lo\n",
      "  CC       src/G72x/g723_40.lo\n",
      "  CC       src/G72x/g72x.lo\n",
      "  CCLD     src/G72x/libg72x.la\n",
      "  CC       src/ALAC/ALACBitUtilities.lo\n",
      "  CC       src/ALAC/ag_dec.lo\n",
      "  CC       src/ALAC/ag_enc.lo\n",
      "  CC       src/ALAC/dp_dec.lo\n",
      "  CC       src/ALAC/dp_enc.lo\n",
      "  CC       src/ALAC/matrix_dec.lo\n",
      "  CC       src/ALAC/matrix_enc.lo\n",
      "  CC       src/ALAC/alac_decoder.lo\n",
      "  CC       src/ALAC/alac_encoder.lo\n",
      "  CCLD     src/ALAC/libalac.la\n",
      "  CC       src/libcommon_la-common.lo\n",
      "  CC       src/libcommon_la-file_io.lo\n",
      "  CC       src/libcommon_la-command.lo\n",
      "  CC       src/libcommon_la-pcm.lo\n",
      "  CC       src/libcommon_la-ulaw.lo\n",
      "  CC       src/libcommon_la-alaw.lo\n",
      "  CC       src/libcommon_la-float32.lo\n",
      "  CC       src/libcommon_la-double64.lo\n",
      "  CC       src/libcommon_la-ima_adpcm.lo\n",
      "  CC       src/libcommon_la-ms_adpcm.lo\n",
      "  CC       src/libcommon_la-gsm610.lo\n",
      "  CC       src/libcommon_la-dwvw.lo\n",
      "  CC       src/libcommon_la-vox_adpcm.lo\n",
      "  CC       src/libcommon_la-interleave.lo\n",
      "  CC       src/libcommon_la-strings.lo\n",
      "  CC       src/libcommon_la-dither.lo\n",
      "  CC       src/libcommon_la-cart.lo\n",
      "  CC       src/libcommon_la-broadcast.lo\n",
      "  CC       src/libcommon_la-audio_detect.lo\n",
      "  CC       src/libcommon_la-ima_oki_adpcm.lo\n",
      "  CC       src/libcommon_la-alac.lo\n",
      "  CC       src/libcommon_la-chunk.lo\n",
      "  CC       src/libcommon_la-ogg.lo\n",
      "  CC       src/libcommon_la-chanmap.lo\n",
      "  CC       src/libcommon_la-windows.lo\n",
      "  CC       src/libcommon_la-id3.lo\n",
      "  CC       src/libcommon_la-nms_adpcm.lo\n",
      "  CCLD     src/libcommon.la\n",
      "  CCLD     src/libsndfile.la\n",
      "  CCLD     programs/sndfile-info\n",
      "  CC       programs/sndfile-play.o\n",
      "  CCLD     programs/sndfile-play\n",
      "  CC       programs/sndfile-convert.o\n",
      "  CCLD     programs/sndfile-convert\n",
      "  CC       programs/sndfile-cmp.o\n",
      "  CCLD     programs/sndfile-cmp\n",
      "  CC       programs/sndfile-metadata-set.o\n",
      "  CCLD     programs/sndfile-metadata-set\n",
      "  CC       programs/sndfile-metadata-get.o\n",
      "  CCLD     programs/sndfile-metadata-get\n",
      "  CC       programs/sndfile-interleave.o\n",
      "  CCLD     programs/sndfile-interleave\n",
      "  CC       programs/sndfile-deinterleave.o\n",
      "  CCLD     programs/sndfile-deinterleave\n",
      "  CC       programs/sndfile-concat.o\n",
      "  CCLD     programs/sndfile-concat\n",
      "  CC       programs/sndfile-salvage.o\n",
      "  CCLD     programs/sndfile-salvage\u001b[0m\n",
      "\u001b[34mmake[2]: Leaving directory '/opt/ml/code/libsndfile-1.0.31'\u001b[0m\n",
      "\u001b[34mmake[1]: Leaving directory '/opt/ml/code/libsndfile-1.0.31'\u001b[0m\n",
      "\u001b[34mmake  install-recursive\u001b[0m\n",
      "\u001b[34mmake[1]: Entering directory '/opt/ml/code/libsndfile-1.0.31'\u001b[0m\n",
      "\u001b[34mmake[2]: Entering directory '/opt/ml/code/libsndfile-1.0.31'\u001b[0m\n",
      "\u001b[34mmake[3]: Entering directory '/opt/ml/code/libsndfile-1.0.31'\n",
      " /usr/bin/mkdir -p '/usr/local/lib'\n",
      " /bin/bash ./libtool   --mode=install /usr/bin/install -c   src/libsndfile.la '/usr/local/lib'\u001b[0m\n",
      "\u001b[34mlibtool: install: /usr/bin/install -c src/.libs/libsndfile.so.1.0.31 /usr/local/lib/libsndfile.so.1.0.31\u001b[0m\n",
      "\u001b[34mlibtool: install: (cd /usr/local/lib && { ln -s -f libsndfile.so.1.0.31 libsndfile.so.1 || { rm -f libsndfile.so.1 && ln -s libsndfile.so.1.0.31 libsndfile.so.1; }; })\u001b[0m\n",
      "\u001b[34mlibtool: install: (cd /usr/local/lib && { ln -s -f libsndfile.so.1.0.31 libsndfile.so || { rm -f libsndfile.so && ln -s libsndfile.so.1.0.31 libsndfile.so; }; })\u001b[0m\n",
      "\u001b[34mlibtool: install: /usr/bin/install -c src/.libs/libsndfile.lai /usr/local/lib/libsndfile.la\u001b[0m\n",
      "\u001b[34mlibtool: install: /usr/bin/install -c src/.libs/libsndfile.a /usr/local/lib/libsndfile.a\u001b[0m\n",
      "\u001b[34mlibtool: install: chmod 644 /usr/local/lib/libsndfile.a\u001b[0m\n",
      "\u001b[34mlibtool: install: ranlib /usr/local/lib/libsndfile.a\u001b[0m\n",
      "\u001b[34mlibtool: finish: PATH=\"/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/sbin\" ldconfig -n /usr/local/lib\u001b[0m\n",
      "\u001b[34m----------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mLibraries have been installed in:\n",
      "   /usr/local/lib\u001b[0m\n",
      "\u001b[34mIf you ever happen to want to link against installed libraries\u001b[0m\n",
      "\u001b[34min a given directory, LIBDIR, you must either use libtool, and\u001b[0m\n",
      "\u001b[34mspecify the full pathname of the library, or use the '-LLIBDIR'\u001b[0m\n",
      "\u001b[34mflag during linking and do at least one of the following:\n",
      "   - add LIBDIR to the 'LD_LIBRARY_PATH' environment variable\n",
      "     during execution\n",
      "   - add LIBDIR to the 'LD_RUN_PATH' environment variable\n",
      "     during linking\n",
      "   - use the '-Wl,-rpath -Wl,LIBDIR' linker flag\n",
      "   - have your system administrator add LIBDIR to '/etc/ld.so.conf'\u001b[0m\n",
      "\u001b[34mSee any operating system documentation about shared libraries for\u001b[0m\n",
      "\u001b[34mmore information, such as the ld(1) and ld.so(8) manual pages.\u001b[0m\n",
      "\u001b[34m----------------------------------------------------------------------\n",
      " /usr/bin/mkdir -p '/usr/local/bin'\n",
      "  /bin/bash ./libtool   --mode=install /usr/bin/install -c programs/sndfile-info programs/sndfile-play programs/sndfile-convert programs/sndfile-cmp programs/sndfile-metadata-set programs/sndfile-metadata-get programs/sndfile-interleave programs/sndfile-deinterleave programs/sndfile-concat programs/sndfile-salvage '/usr/local/bin'\u001b[0m\n",
      "\u001b[34mlibtool: install: /usr/bin/install -c programs/.libs/sndfile-info /usr/local/bin/sndfile-info\u001b[0m\n",
      "\u001b[34mlibtool: install: /usr/bin/install -c programs/.libs/sndfile-play /usr/local/bin/sndfile-play\u001b[0m\n",
      "\u001b[34mlibtool: install: /usr/bin/install -c programs/.libs/sndfile-convert /usr/local/bin/sndfile-convert\u001b[0m\n",
      "\u001b[34mlibtool: install: /usr/bin/install -c programs/.libs/sndfile-cmp /usr/local/bin/sndfile-cmp\u001b[0m\n",
      "\u001b[34mlibtool: install: /usr/bin/install -c programs/.libs/sndfile-metadata-set /usr/local/bin/sndfile-metadata-set\u001b[0m\n",
      "\u001b[34mlibtool: install: /usr/bin/install -c programs/.libs/sndfile-metadata-get /usr/local/bin/sndfile-metadata-get\u001b[0m\n",
      "\u001b[34mlibtool: install: /usr/bin/install -c programs/.libs/sndfile-interleave /usr/local/bin/sndfile-interleave\u001b[0m\n",
      "\u001b[34mlibtool: install: /usr/bin/install -c programs/.libs/sndfile-deinterleave /usr/local/bin/sndfile-deinterleave\u001b[0m\n",
      "\u001b[34mlibtool: install: /usr/bin/install -c programs/.libs/sndfile-concat /usr/local/bin/sndfile-concat\u001b[0m\n",
      "\u001b[34mlibtool: install: /usr/bin/install -c programs/.libs/sndfile-salvage /usr/local/bin/sndfile-salvage\n",
      " /usr/bin/mkdir -p '/usr/local/share/doc/libsndfile'\n",
      " /usr/bin/install -c -m 644 docs/index.md docs/libsndfile.jpg docs/libsndfile.css docs/print.css docs/api.md docs/command.md docs/bugs.md docs/formats.md docs/sndfile_info.md docs/new_file_type_howto.md docs/win32.md docs/FAQ.md docs/lists.md docs/embedded_files.md docs/octave.md docs/tutorial.md '/usr/local/share/doc/libsndfile'\n",
      " /usr/bin/mkdir -p '/usr/local/include'\n",
      " /usr/bin/install -c -m 644 include/sndfile.hh '/usr/local/include'\n",
      " /usr/bin/mkdir -p '/usr/local/share/man/man1'\n",
      " /usr/bin/install -c -m 644 man/sndfile-info.1 man/sndfile-play.1 man/sndfile-convert.1 man/sndfile-cmp.1 man/sndfile-metadata-get.1 man/sndfile-metadata-set.1 man/sndfile-concat.1 man/sndfile-interleave.1 man/sndfile-deinterleave.1 man/sndfile-salvage.1 '/usr/local/share/man/man1'\n",
      " /usr/bin/mkdir -p '/usr/local/include'\n",
      " /usr/bin/install -c -m 644 include/sndfile.h '/usr/local/include'\n",
      " /usr/bin/mkdir -p '/usr/local/lib/pkgconfig'\n",
      " /usr/bin/install -c -m 644 sndfile.pc '/usr/local/lib/pkgconfig'\u001b[0m\n",
      "\u001b[34mmake[3]: Leaving directory '/opt/ml/code/libsndfile-1.0.31'\u001b[0m\n",
      "\u001b[34mmake[2]: Leaving directory '/opt/ml/code/libsndfile-1.0.31'\u001b[0m\n",
      "\u001b[34mmake[1]: Leaving directory '/opt/ml/code/libsndfile-1.0.31'\u001b[0m\n",
      "\u001b[34minstall_sndfile.sh: 1: %%bash: not found\u001b[0m\n",
      "\u001b[34m--2023-01-08 22:49:00--  https://github.com/libsndfile/libsndfile/releases/download/1.0.31/libsndfile-1.0.31.tar.bz2\u001b[0m\n",
      "\u001b[34mResolving github.com (github.com)... 192.30.255.113\u001b[0m\n",
      "\u001b[34mConnecting to github.com (github.com)|192.30.255.113|:443... connected.\u001b[0m\n",
      "\u001b[34mHTTP request sent, awaiting response... 302 Found\u001b[0m\n",
      "\u001b[34mLocation: https://objects.githubusercontent.com/github-production-release-asset-2e65be/3182884/4698b000-5e48-11eb-845f-294a65d37d7c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230108%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230108T224900Z&X-Amz-Expires=300&X-Amz-Signature=1ac8f94ccd7c47446695e93603aa1f72401eebc419ba3a796fcd38cf22d78fb9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=3182884&response-content-disposition=attachment%3B%20filename%3Dlibsndfile-1.0.31.tar.bz2&response-content-type=application%2Foctet-stream [following]\u001b[0m\n",
      "\u001b[34m--2023-01-08 22:49:00--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/3182884/4698b000-5e48-11eb-845f-294a65d37d7c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230108%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230108T224900Z&X-Amz-Expires=300&X-Amz-Signature=1ac8f94ccd7c47446695e93603aa1f72401eebc419ba3a796fcd38cf22d78fb9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=3182884&response-content-disposition=attachment%3B%20filename%3Dlibsndfile-1.0.31.tar.bz2&response-content-type=application%2Foctet-stream\u001b[0m\n",
      "\u001b[34mResolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\u001b[0m\n",
      "\u001b[34mConnecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\u001b[0m\n",
      "\u001b[34mHTTP request sent, awaiting response... 200 OK\u001b[0m\n",
      "\u001b[34mLength: 875335 (855K) [application/octet-stream]\u001b[0m\n",
      "\u001b[34mSaving to: ‘libsndfile-1.0.31.tar.bz2’\n",
      "     0K .......... .......... .......... .......... ..........  5% 5.89M 0s\n",
      "    50K .......... .......... .......... .......... .......... 11% 16.8M 0s\n",
      "   100K .......... .......... .......... .......... .......... 17% 10.9M 0s\n",
      "   150K .......... .......... .......... .......... .......... 23% 42.9M 0s\n",
      "   200K .......... .......... .......... .......... .......... 29% 10.2M 0s\n",
      "   250K .......... .......... .......... .......... .......... 35%  104M 0s\n",
      "   300K .......... .......... .......... .......... .......... 40% 51.1M 0s\n",
      "   350K .......... .......... .......... .......... .......... 46% 1.13M 0s\n",
      "   400K .......... .......... .......... .......... .......... 52%  119M 0s\n",
      "   450K .......... .......... .......... .......... .......... 58%  105M 0s\n",
      "   500K .......... .......... .......... .......... .......... 64%  100M 0s\n",
      "   550K .......... .......... .......... .......... .......... 70% 94.4M 0s\n",
      "   600K .......... .......... .......... .......... .......... 76%  275M 0s\n",
      "   650K .......... .......... .......... .......... .......... 81% 92.7M 0s\n",
      "   700K .......... .......... .......... .......... .......... 87% 10.9M 0s\n",
      "   750K .......... .......... .......... .......... .......... 93%  157M 0s\n",
      "   800K .......... .......... .......... .......... .......... 99%  839K 0s\n",
      "   850K ....                                                  100% 9192G=0.1s\u001b[0m\n",
      "\u001b[34m2023-01-08 22:49:01 (6.27 MB/s) - ‘libsndfile-1.0.31.tar.bz2’ saved [875335/875335]\u001b[0m\n",
      "\u001b[34mconfigure: WARNING: Touching files in directory tests/.\u001b[0m\n",
      "\u001b[34mar: `u' modifier ignored since `D' is the default (see `U')\u001b[0m\n",
      "\u001b[34mar: `u' modifier ignored since `D' is the default (see `U')\u001b[0m\n",
      "\u001b[34mar: `u' modifier ignored since `D' is the default (see `U')\u001b[0m\n",
      "\u001b[34mar: `u' modifier ignored since `D' is the default (see `U')\u001b[0m\n",
      "\u001b[34mar: `u' modifier ignored since `D' is the default (see `U')\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\u001b[0m\n",
      "\u001b[34mFile \"run_wav2vec2_pretraining_no_trainer_sagemaker.py\", line 820, in <module>\n",
      "    main()\u001b[0m\n",
      "\u001b[34mFile \"run_wav2vec2_pretraining_no_trainer_sagemaker.py\", line 457, in main\n",
      "    raw_datasets = load_from_disk(args.dataset_s3_path,fs=s3)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/datasets/load.py\", line 1757, in load_from_disk\n",
      "    return DatasetDict.load_from_disk(dataset_path, fs, keep_in_memory=keep_in_memory)\u001b[0m\n",
      "\u001b[34mFile \"/opt/conda/lib/python3.8/site-packages/datasets/dataset_dict.py\", line 771, in load_from_disk\n",
      "    dataset_dict[k] = Dataset.load_from_disk(dataset_dict_split_path, fs, keep_in_memory=keep_in_memory)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py\", line 1102, in load_from_disk\n",
      "    fs.download(src_dataset_path, dataset_path.as_posix(), recursive=True)\u001b[0m\n",
      "\u001b[34mFile \"/opt/conda/lib/python3.8/site-packages/fsspec/spec.py\", line 1265, in download\n",
      "    return self.get(rpath, lpath, recursive=recursive, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fsspec/spec.py\", line 801, in get\n",
      "    self.get_file(rpath, lpath, **kwargs)\u001b[0m\n",
      "\u001b[34mFile \"/opt/conda/lib/python3.8/site-packages/fsspec/spec.py\", line 776, in get_file\n",
      "    segment_len = outfile.write(data)\u001b[0m\n",
      "\u001b[34mOSError: [Errno 28] No space left on device\u001b[0m\n",
      "\u001b[34mwandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.\u001b[0m\n",
      "\u001b[34mwandb: - 0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\u001b[0m\n",
      "\u001b[34mwandb: \\ 0.003 MB of 0.035 MB uploaded (0.000 MB deduped)\u001b[0m\n",
      "\u001b[34mwandb: Synced huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516-acmbbn-algo-1: https://wandb.ai/mutisya/wav2vec2-pretrain-swahili-radio2022-1/runs/huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516-acmbbn-algo-1\u001b[0m\n",
      "\u001b[34mwandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\u001b[0m\n",
      "\u001b[34mwandb: Find logs at: ./wandb/run-20230108_224855-huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516-acmbbn-algo-1/logs\u001b[0m\n",
      "\u001b[34m2023-01-08 23:19:57,854 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-01-08 23:19:57,855 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-01-08 23:19:57,855 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2023-01-08 23:19:57,855 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"OSError: [Errno 28] No space left on device\n",
      " wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.\n",
      " wandb: - 0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      " wandb: \\ 0.003 MB of 0.035 MB uploaded (0.000 MB deduped)\n",
      " wandb: Synced huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516-acmbbn-algo-1: https://wandb.ai/mutisya/wav2vec2-pretrain-swahili-radio2022-1/runs/huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516-acmbbn-algo-1\n",
      " wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      " wandb: Find logs at: ./wandb/run-20230108_224855-huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516-acmbbn-algo-1/logs\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.8 run_wav2vec2_pretraining_no_trainer_sagemaker.py --adam_beta1 0.9 --adam_beta2 0.98 --adam_epsilon 1e-06 --dataset_config_names train --dataset_s3_path s3://dataset-staging-2022/swahili_radio_yt_2022_v0.2/ --dataset_split_names train --dataset_use_auth_token True --gradient_accumulation_steps 4 --gradient_checkpointing True --hub_model_id mutisya/wav2vec2-pretrain-swahili-radio2022-sage-1 --hub_token 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 --learning_rate 0.002 --logging_steps 1 --max_duration_in_seconds 30.5 --max_train_steps 20000 --min_duration_in_seconds 2.0 --model_name_or_path patrickvonplaten/wav2vec2-base-v2 --num_warmup_steps 32000 --output_dir ./wav2vec2-pretrain-swahili-radio2022-1 --per_device_eval_batch_size 4 --per_device_train_batch_size 4 --push_to_hub True --saving_steps 10000 --weight_decay 0.01\"\u001b[0m\n",
      "\u001b[34m2023-01-08 23:19:57,855 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2023-01-08 23:20:09 Uploading - Uploading generated training model\n",
      "2023-01-08 23:20:09 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"OSError: [Errno 28] No space left on device\n wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.\n wandb: - 0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\n wandb: \\ 0.003 MB of 0.035 MB uploaded (0.000 MB deduped)\n wandb: Synced huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516-acmbbn-algo-1: https://wandb.ai/mutisya/wav2vec2-pretrain-swahili-radio2022-1/runs/huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516-acmbbn-algo-1\n wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n wandb: Find logs at: ./wandb/run-20230108_224855-huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516-acmbbn-algo-1/logs\"\nCommand \"/opt/conda/bin/python3.8 run_wav2vec2_pretraining_no_trainer_sagemaker.py --adam_beta1 0.9 --adam_beta2 0.98 --adam_epsilon 1e-06 --dataset_config_names train --dataset_s3_path s3://dataset-staging-2022/swahili_radio_yt_2022_v0.2/ --dataset_split_names",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-93cbd06b9cbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#Starts the training job using the fit function, training takes approximately 2 hours to complete.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m huggingface_estimator.fit({'train': 's3://dataset-staging-2022/swahili_radio_yt_2022_v0.2/'},\n\u001b[0;32m---> 28\u001b[0;31m                          job_name=TRAINING_JOB_NAME)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_StepArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve_caller_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2247\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2249\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2250\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   4111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4113\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4115\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3645\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3646\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3647\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3648\u001b[0m             )\n\u001b[1;32m   3649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"OSError: [Errno 28] No space left on device\n wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.\n wandb: - 0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\n wandb: \\ 0.003 MB of 0.035 MB uploaded (0.000 MB deduped)\n wandb: Synced huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516-acmbbn-algo-1: https://wandb.ai/mutisya/wav2vec2-pretrain-swahili-radio2022-1/runs/huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516-acmbbn-algo-1\n wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n wandb: Find logs at: ./wandb/run-20230108_224855-huggingface-wav2vec2-pretrain-swahili-radio2022-1673215516-acmbbn-algo-1/logs\"\nCommand \"/opt/conda/bin/python3.8 run_wav2vec2_pretraining_no_trainer_sagemaker.py --adam_beta1 0.9 --adam_beta2 0.98 --adam_epsilon 1e-06 --dataset_config_names train --dataset_s3_path s3://dataset-staging-2022/swahili_radio_yt_2022_v0.2/ --dataset_split_names"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH= f's3://{BUCKET}/{PREFIX}/{TRAINING_JOB_NAME}/output/'\n",
    "\n",
    "env_variables = {\n",
    "    'HF_API_TOKEN':HF_API_TOKEN,\n",
    "    'HF_MODEL_ID': HF_MODEL_ID\n",
    "}\n",
    "huggingface_estimator = HuggingFace(entry_point='run_wav2vec2_pretraining_no_trainer_sagemaker.py',\n",
    "                                    source_dir='./sagemaker/pretrain_wav2vec/pytorch',\n",
    "                                    output_path= OUTPUT_PATH, \n",
    "                                    instance_type='ml.g5.2xlarge',\n",
    "                                    instance_count=1,\n",
    "                                    volume_size=1024,\n",
    "                                    transformers_version='4.17.0',\n",
    "                                    pytorch_version='1.10.2',\n",
    "                                    #pytorch_version='1.8.0',\n",
    "                                    py_version='py38',\n",
    "                                    #py_version='py37',\n",
    "                                    role=ROLE,\n",
    "                                    use_spot_instances=True,  # Use a spot instance \n",
    "                                    max_run=259200,  # Max training time\n",
    "                                    max_wait=270000,  # Max training time + spot waiting time\n",
    "                                    hyperparameters = hyperparameters,\n",
    "                                    metric_definitions = metric_definitions,\n",
    "                                    environment = env_variables\n",
    "                                   )\n",
    "\n",
    "#Starts the training job using the fit function, training takes approximately 2 hours to complete.\n",
    "huggingface_estimator.fit({'train': 's3://dataset-staging-2022/swahili_radio_yt_2022_v0.2/'},\n",
    "                         job_name=TRAINING_JOB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the training logs you can see that, after 10 epochs of training, and model evaluation metrics wer can achieve around 0.32 for the subset of SUPERB dataset. You can increase the number of epochs or use the full dataset to improve the model further. "
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]"
  },
  "toc-showtags": true,
  "vscode": {
   "interpreter": {
    "hash": "3e4c26631640e9b131893bef564fd60ba2dcf8108f36d999dbaba747635dc18b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
